21. Система прерываний. Виды прерываний. Механизм обработки прерываний по шагам. Задачи, решаемые механизмом прерываний. Сторожевой таймер.	1
22. Параллелизм уровня задач. Проблемы совмещения, изоляции и взаимодействия задач между собой. Методы разрешения данных проблем (с точки зрения опыта программиста и пользователя): распределение по адресному пространству, банки памяти, сегментная организация памяти и виртуальная память.	3
23. Сегментная и виртуальная память. Решаемые задачи и принципы работы. Проблема фрагментации. Достоинства и недостатки.	5
24. Иерархия памяти (явная и скрытая). Виды памяти. Особенности использования на практике. Устройство памяти с произвольным доступом. Устройство и принцип работы ROM, SRAM, DRAM ячеек.	7
25. Механизм кеширования в компьютерных системах, принцип локальности. Функционирование кеш памяти процессора (чтение, запись). Виды кеш промахов. Механизм вытеснения (LRU, PLRU).	10
26. Устройство кеш-памяти процессора. Ассоциативность кеш-памяти (полностью ассоциативная, прямое отображение, множественно-ассоциативный кеш). Принципы работы. Детальное описание принципов работы кеш-памяти с разными вариантами ассоциативности.	12
27. Иерархия кеш-памяти процессора. Разделённый/унифицированный, включающий/исключающий, частный/общий. Причины множества уровней кеша. Типовые уровни кеша в современных процессорах.	14
28. Когерентность кеш-памяти. Возможные состояния кеш линий. Механизмы обмена информацией между кешами: справочник, отслеживание и перехват. CAP теорема.	15
29. Закон Мура. Закон Деннарда. Закон Амдала. Power-wall. Memory-wall. Их роль в развитии компьютерных систем. Источники роста производительности процессоров тогда и сегодня.	16
30. Проблема обеспечения реального времени в современных компьютерных системах. Влияние параллелизма уровня инструкций, языков программирования высокого уровня, многозадачности и организации памяти.	17
21. Система прерываний. Виды прерываний. Механизм обработки прерываний по шагам. Задачи, решаемые механизмом прерываний. Сторожевой таймер.
Система прерываний заключается в “сиюминутном” реагировании на зарегистрированные условия для выполнения прерывания, вне зависимости от желания отдать управление текущей задачи. 
Механизм работы:
Выполнение основного потока (задачи)
Запрос прерывания (внешнее по отношению к процессору событие, сигнализирующее о необходимости начать прерывание)
Сохранение адреса возврата
Вызов обработчика прерываний (обычный код, расположенный по определенному адресу, который находится в векторе прерываний)
Завершение работы обработчика
Восстановление адреса возврата
Продолжение основного потока
Источники прерываний:
Аппаратные
Внешние (асинхронные (не синхронизированы с тактом процессора, могут произойти в любой момент. Например ввод, таймер, нажатие кнопки)
Внутренние (синхронные. Например деление на 0, ошибка доступа к памяти)
Программные (происходит системный вызов из пользовательской программы, который оповещает ОС о потребности, после чего ОС ее выполняет) характеризуются инициацией прерывания из процесса, а не из вне
Управление прерываниями реализуется контроллером прерываний (аппаратно)
Прерывания разделяются на:
Конкурирующие (приоритеты, очереди)
Маскируемые/немаскируемые (контроллером; заглушить или больше слушать)
Относительные/абсолютные (относительные не позволяют вложенность прерываний, абсолютные позволяют)
По виду события/прерывания
по фронту
по уровню 
по сообщению (не просто флаг, а имеет запакованные данные)
по дверному звонку 
Как правило, прерывания используются для работы с периферийными устройствами. С помощью прерываний также может быть реализована многозадачность, отладка программ, эмуляция определённых устройств и т.д. Механизм прерываний позволяет исключить пустой простой в ожидании какого-то события, вместо того чтобы ждать сигнала что событие произошло во время выполнения задачи.
Сторожевой таймер (рус.) – аппаратно реализованная схема контроля от зависания системы
Сторожевой таймер (англ.) – программное или аппаратное обеспечение, которое используется для обнаружения неисправностей компьютера и восстановления после них.
Простыми словами это устройство, задача которого определить, что система находится в каком-то нестандартном неадекватном состоянии. При нормальной работе системы должен сбрасываться раз в какое-то время, если этого не происходит (т.е. поведение некорректно) происходит аварийная перезагрузка.
22. Параллелизм уровня задач. Проблемы совмещения, изоляции и взаимодействия задач между собой. Методы разрешения данных проблем (с точки зрения опыта программиста и пользователя): распределение по адресному пространству, банки памяти, сегментная организация памяти и виртуальная память.
Параллелизм уровня задач подразумевает запоминание состояния, переключение инструкций, восстановление предыдущего. При работе с несколькими задачами важно не допустить их нежелательного/неправильного смешивания и правильно смешать их работу.
Проблемы совмещения, изоляции и взаимодействия задач между собой появляются, так как при параллелизме возникает важный вопрос о синхронизации работы задач, их состояний, распределении памяти под них, переключении потоков. Одна задача не должна незапланированно влиять на работу второй, ровно как и наоборот (или даже не быть частично замещена ее инструкциями при отсутствии изоляции)
Необходимо изолировать:
Адреса инструкций (переходы)
Динамические библиотеки
Адреса статических данных и переменных
Динамическую память (кучу)
Автоматическую память (стек)
Реализуется либо на уровне компиляции (мы говорим компилятору адреса), либо на уровне линковки (отдельные программные модули сами располагаем на адреса), либо в рантайме.
Распределение по адресному пространству супер неудобная вещь, так как с точки зрения пользователя даже при вызове команды ls линкуса придется руками писать адреса, на которых она будет работать 
Расположенные на системной плате и платах памяти микросхемы (DIP, SIMM, SIPP и DIMM) организуются в банки памяти. Используются при:
Память имеет большее адресное пространство, чем процессор
Расширение машинного слова (если шина памяти 8, а процессора 16, эти 16 бьются на 2 банка памяти по 8)
Переключение режима работы (аппаратная изоляция)
Изоляция задач (редко, мультиплексором)
Сегментная организация памяти – разделении блоков программы на сегменты (инструкции, данные, стек) с фиксированным размером, каждому из которых можно дать права доступа. (см. вопрос 23)
Виртуальная память – концепция предоставления каждому процессу “целой” памяти, что он будет думать что он работает в собственном адресном пространстве. А эти виртуальные адреса будут маппиться на физические. 
Принцип работы заключается в разделении виртуальной памяти на страницы, к которым обращается процессор, эта страница отображается через таблицу сопоставления на физическую память (с учетом контекста что это за процесс). Если места не хватает, сохраняется на жесткий диск. Здесь возникает иерархия памяти.
Взаимодействие main потока (с которым стартует железка), прерываний и потоков (работают в адресном пространстве процессора с прямым доступом к его данным) обуславливается работой в едином адресном пространстве.
Взаимодействие потоков (вместе с main и прерываниями) характеризуется проблемой непредсказуемости последовательности исполнения инструкций с недетерминированным результатом. Решается искусственной синхронизацией процессов:
Атомарные операции (compare & swap – без прерывания проверить занят ли lock, если нет – занять и записать, если нет – не получит доступ; store conditional – записывание в ячейку памяти при выполнении условия)
Mutex, Semaphore (реализуются с помощью механизмов атомарности)
Транзакции (работа с памятью как с бд; сначала чет меняешь потом “коммитишь” изменения)
Промисы, фьючерсы, actor-model…
Взаимодействие процессов 
Shared memory (память доступная для записи нескольким процессам)
Signals (подобие прерываний, один процесс посылает сигнал другому, который на него реагирует)
IO: сетевые, файлы, pipe’ы

23. Сегментная и виртуальная память. Решаемые задачи и принципы работы. Проблема фрагментации. Достоинства и недостатки.
Сегментная память – заключается в изначальном разделении блоков программы на сегменты (инструкции, данные, стек) с фиксированным размером, каждому из которых можно дать права доступа.
Сегментная адресация памяти – способ логической адресации, где адрес = сегмент + смещение внутри него, где сегмент – выделенная область адресного пространства определенного размера, а смещение – адрес ячейки памяти относительно начала сегмента
Особенности:
Отсутствие излишних прав на сегменты (инструкции только читать => невозможно перезаписать и т.д.)
Контроль целостности данных, отсутствие проблемы переполненных буферов (изначально прочитали допустимый размер)
Возможность программного управления каждым сегментом
Решает проблемы:
Коллизий по данным, адресам или инструкциям за счет независимой адресации внутри сегментов
Управление доступом (r/w). Запрет доступа к чужим сегментам
Взаимодействие задач через общий сегмент
Изоляция программных модулей, динамических библиотек
Перекрытие сегментов (наслоение)
Достоинства:
Таблицы сегментов малы => легко работать
Таблицы сегментов просты в обработке и перемещении 
Средние размеры сегментов больше, чем размеры страниц, что позволяет хранить в них больше данных процесса
Отсутствует внутренняя фрагментация
Недостатки:
Сложна в поддержке со стороны компилятора, ПО (выделение сегментов подразумевает четкое разделение по назначению, что ложится на плечи не самых умных разрабов), обязательно участие программиста
Подвержена серьезной внешней фрагментации
Устаревшее, ограниченная поддержка линуксом
Виртуальная память – концепция предоставления каждому процессу “целой” памяти, что он будет думать что он работает в собственном адресном пространстве. А эти виртуальные адреса будут маппиться на физические. 
Принцип работы заключается в разделении виртуальной памяти на страницы, к которым обращается процессор, эта страница отображается через таблицу сопоставления на физическую память (с учетом контекста что это за процесс). Если места не хватает, сохраняется на жесткий диск. Здесь возникает иерархия памяти.
Достоинства:
Прозрачно для программиста изолировать задачи. Мы не думаем об этом 
Нелинейное физическое размещение данных (страницы процесса не обязательно хранятся последовательно)
Нет необходимости фиксировать объем памяти, используемый задачей
Возможность использовать больше памяти, чем есть физически (вовлекается диск)
Наложение прав доступа на страницы, что позволяет достичь изоляции
Недостатки:
Большой объем таблиц страниц, длительный поиск
Высокие накладные расходы (IO, перенос страниц и т.д.)
Непредсказуемая длительность доступа к памяти (может быть на диске)
Высокая сложность реализации
Высокая внутренняя фрагментация
Внутренняя фрагментация – блоки памяти фиксированного размера, при заполнении их меньшим объемом данных потеря памяти
Внешняя фрагментация – блоки памяти произвольного размера, после освобождения неиспользуемого может быть к примеру 1Мб, а нужно 2Мб => пустое окно => потеря памяти. Проблема плотной укладки
24. Иерархия памяти (явная и скрытая). Виды памяти. Особенности использования на практике. Устройство памяти с произвольным доступом. Устройство и принцип работы ROM, SRAM, DRAM ячеек.
Иерархия памяти – концепция разделения различных видов памяти по их стоимости, вместимости и скорости доступа. На первом (нижнем) уровне располагаются жесткие диски (металлические пластины с читающей головкой), располагающие большой вместимостью, однако низкой скоростью доступа за счет физических поворотов и манипуляций пишущей/читающей головкой. На втором – SSD диски. Скорость растет за счет отсутствия манипуляции физическими элементами. На третьем – SD-RAM как основная память компьютера. На вершине – кеши трех уровней и регистры процессора. Самая дорогая, малого объема и быстрая память.
Явная иерархия – концепция работы с иерархией памяти программистом напрямую. Сопоставление требований по объему и скорости и параметрами памяти. Концептуально хорошо, но правильный выбор дальше чем между оперативой и диском среднего ума программистам мало подвластен. Возникает проблема, что даже правильная работа с памятью с выходом нового железа будет работать плохо, т.к. память будет другая
Скрытая иерархия – работа с памятью отдана на управление ОС с железом, решения принимаются в рантайме. Участие программиста особо не требуется, с выходом новой аппаратуры ничего не ломается. Сейчас преобладает.
Типы доступа к памяти:
С произвольным доступом (RAM) – можно выбрать любую ячейку памяти и прочитать из нее.
С последовательным доступом (жесткие диски, магнитные ленты) – пишем последовательно, а не в рандомные ячейки. Обладает высокой скоростью последовательной записи/чтения (когда не надо магнитную головку передвигать, а просто писать)
Гибридные (библиотека магнитных лент, векторные операции) – данные записаны последовательно, но конкретную магнитную ленту можно взять рандомно
Устройство памяти с произвольным доступом (RAM):
Есть шина адреса, куда приходит то машинное слово, которое мы хотим считать, которое идет в дешифратор (преобразует адрес в один бит), который активирует нужную линию, которая хранит набор битов (хранящихся каждый в своей ячейке). Этот набор битов идет на шину данных. Такая конструкция не позволяет обратиться к нескольким словам одновременно (выбирается одна линия), а также в настоящее время это супер большие массивы таких слов, как следствие большая энергетическая емкость => работает достаточно медленно.

Ячейки, хранящие 1 бит слова, могут быть реализованы по-разному:
Flip-flop (триггер) – ~20 транзисторов, маленькие временные задержки (пс), хранят порядка 1-5 Кб, дорого стоят
ROM (read only memory) – особо не требует транзисторов (≤1) 
SRAM – 6 транзисторов, задержки 1-10 нс, хранят 10Кб-10Мб, 1000$
DRAM – 1 транзистор, 80 нс, 10 Гб, ~10$
ROM – энергонезависимая память только для чтения. На bitline всегда подается 1, после чего есть 2 варианта. Либо транзистор замыкает линию с 0 и читается 0, либо не замыкаем и происходит прямая передача 1. Реализуется либо физическим (не)размещением транзисторов на производстве, либо пережиганием перемычек при однократном программировании.

SRAM – статическая память (пока есть питание), которая хранит данные при помощи состояния групп транзисторов (4 инвертора и 2 для доступа). При разных значениях на инвертированном и не инвертированный bitline все ок, схема самоподдерживающаяся за счет 2 инверторов в цикле. Если значения на обоих bitline одинаковые, происходит “притягивание” к 0 или 1, что при считывании учитывается. Запись аналогична, за исключением что мы сами выставляем то, что нам нужно записать и ждем, пока произойдет это притягивание в схеме. Обеспечивает быстрый доступ на чтение и запись и обладает низкой плотностью ячеек (требуется много транзисторов)

DRAM – динамическая память, состояние хранится в конденсаторе. Требует постоянного поддержания (перезаписывания), в силу физики конденсатора, что снять с него заряд без его разрядки нельзя и токов потерь. Такая регенерация заряда увеличивает длительность доступа и блокирует доступ к памяти во время ее исполнения. 
25. Механизм кеширования в компьютерных системах, принцип локальности. Функционирование кеш памяти процессора (чтение, запись). Виды кеш промахов. Механизм вытеснения (LRU, PLRU).
Идея, способствовавшая возникновению кеша, это расположить часто используемые процессором данные динамически в самой быстрой памяти. 
В основе этой идеи заложено выполнение принципов временной и пространственной локальности данных. Локальность данных говорит, что обращение к данным носит неслучайный характер, все данные программы лежат в одном месте памяти, а не раскиданы. Локальность времени – о предсказании с высокой вероятностью потребности считать данные.
Сейчас кеши применяются на всех уровнях компьютерных систем. Несмотря на это, существует противоречие: при большом объеме данных со случайным распределением кеш особо не даст производительности (из-за отсутствия локальности), при большой локальности нет смысла делать большой кеш, так как он будет простаивать. 
Функционирование кеша:
Состоит из набора кеш-линий (хранит номер, тег соответствия физ. памяти и данные)
Кеш-линия ассоциирована с элементом в медленной памяти
Кеш-линия имеет идентификатор (тег), определяющий соответствие
Доступ к памяти прозрачно для программиста
Память может быть изменена все зависимости от кеша: DMA, другое ядро. Перестает быть пассивной, может по своему усмотрению остановить процессор при доступе к ней, изменить данные в ней 
Важно отметить что доступ к ней занимает время, вследствие чего может замедлять скорость доступа.
Чтение: 
Тег найден (кеш-попадание) – процессор обратился с адресом, который соответствует существующей кеш-линии в кеше. Кеш достает эти данные и отдает процессору
Тег не найден (кеш-промах) – обратились, данных там нет, кеш начинает пытаться достать эти данные из памяти. Для этого ему надо найти в какую линию писать. Если есть пустая (или есть такая, данные которой точно уже не понадобятся) – подходит, пишем туда. Если нет – принимаем решение о вытеснении линии.
Длительность получения данных из кеша произвольна (многоуровненые кеши, блокировка памяти например при восстановлении или работе с DMA). Главная численная характеристика кеша – уровень попадания, то есть процентное соотношение hit / miss.
Запись (при кеш-попадании): 
Немедленная запись – кеш в роли транзитной точки, данные будут записаны в ячейку памяти и вообще не обязательно будут сохранены в кеше. Иногда медленнее, чем без кеша 
Отложенная запись – сначала запись в быстрый буфер-кеш, затем запись всего буфера в память. Это быстрее, но управление данными кеш-линии усложняется (сопоставление версий данных в кеше и памяти). Кроме того свойственна группировка изменений и сокрытие промежуточных состояний (плохо для IO). 
Гибридные варианты – например немедленная запись с буферизацией 
Запись (при кеш-промахе):
Запись с размещением – пишем данные, а в памяти их нет. Сначала данные из памяти записываются в кеш, затем кеш обновляется и происходит запись в память
Запись без размещения – запись производится напрямую в память или через буфер (группировка изменений)
Виды кеш-промахов:
Чтение данных – обладает средней задержкой. Может компенсироваться параллелизмом уровня инструкций (инструкции, для которых нет данных откладываются процессором на потом
Запись данных – обладают минимальной задержкой, так как данные записываются в буфер и запись откладывается
Чтение инструкций – большая задержка. Нет никаких способов пофиксить, так как предугадать инструкцию не представляется возможным. Процессор простаивает в ожидании инструкции. Предотвращает это прогревание кеша, заполняя его инструкциями, которые наиболее вероятно понадобятся
Механизм вытеснения – то, как ведет себя кеш при отсутствии свободных линий для записи. Работает по логике то, чем мы давно не пользовались, маловероятно что вообще понадобится.
Least Recently Used (LRU) – заключается в маркировке записей временем последнего доступа (записи или чтения). Вытесняется с наиболее старой. Плох постоянным обновлением данных, которые еще и нужно хранить.
Pseudo-LRU (PLRU) – поиск наиболее ранней модификации с помощью приближения, а не точного времени (бинарное дерево). При проходя через каждый уровень мы инвертируем значения и при следующем проходе пойдем по альтернативному пути. При этом инверсия пути от корня до листа (лист это всегда кеш-линия) – кеш-попадание 

26. Устройство кеш-памяти процессора. Ассоциативность кеш-памяти (полностью ассоциативная, прямое отображение, множественно-ассоциативный кеш). Принципы работы. Детальное описание принципов работы кеш-памяти с разными вариантами ассоциативности.
Устройство кеша представляет собой совокупность памяти (хранение тегов и данных) и логики.
Логика реализует:
Поиск кеш-линии по тегу (компараторы, есть нужная линия или нет)
Вытеснение, replacement (определение ненужной кеш-линии)
Предзагрузка (prefetch) данных и инструкций (угадывание данных которые нам понадобятся в ближайшем будущем)
Взаимодействие с памятью (группировка операций и т.д)
Синхронизации кешей разных уровней
Линейное увеличение памяти кеша (количества кеш-линий) влечет за собой увеличение объема логики. При проектировании стоит выбор скорости и стоимости (16 линий проверят 8 компараторов за 2 такта или 4 за 4)
Основа кеш-памяти – ассоциативность. То есть политика размещения памяти в кеше для оптимизации поиска (баланс между логикой, памятью и временем поиска).
Теги, по которым происходит поиск не хранятся целиком для экономии памяти и ресурсов (избавляемся от больших компараторов)
Кеш память с разными вариантами ассоциативности:
Полностью ассоциативный кеш – дает возможность каждой кеш-линии быть связанной с любым блоком из памяти. С точки зрения схемотехники адрес (6 бит, так как остальные 2 характеризуют 4 адреса ячейки памяти кеша, а это нам не важно, т.к. мы всегда читаем по 4), к которому обращается процессор, загружается в компаратор вместе с тегом. Если совпали, получаем 1 на нужной кеш-линии. Все супер классно, но на каждую линию нужен компаратор, что будет занимать огромную площадь при большом количестве линий

Кеш с прямым отображением – одной кеш-линии позволено хранить только один блок из ограниченного набора. Адрес от процессора бьется на 3 части (младшая, которая адресуется внутри кеш-линии и нам не интересна, средняя – номер линии). Старшие биты попадают в мультиплексор, по средним битам выбирается линия, эти старшие биты попадают на компаратор и там сравнивается. Такой подход позволяет сократить память для хранения тегов, только один компаратор. Плохо тем, что увеличивается количество кеш-промахов из-за зашитой логики хранения в одной линии одного из заданного набора блоков

Множественно-ассоциативный кеш – гибридный вариант первых двух. Несколько кешей с прямым отображением ставятся в параллель (каждый из которых образует банк памяти), а поиск нужной линии происходит по банкам памяти. При этом 2 банка памяти могут хранить один и тот же набор блоков, что решает проблему множественных кеш-промахов. Считается оптимальным по площади и производительности

27. Иерархия кеш-памяти процессора. Разделённый/унифицированный, включающий/исключающий, частный/общий. Причины множества уровней кеша. Типовые уровни кеша в современных процессорах.
В целом разнообразие кешей определяется технологиями устройства ячеек памяти и его устройством (например ассоциативностью). Это зависит от его задачи: повышении скорости доступа, синхронизации проц. ядер или оптимизации интерфейсов. В настоящее время в компьютерах ограничивается 3 уровнями кешей (иногда 4). 
Способы организации многоуровневых кешей:
Разделенный / унифицированный – организация несколькими / одним банком памяти. Разделение по типу данных (инструкции и данные) позволяет шагнуть в Гарвардскую архитектуру, снизить количество коллизий по данным за счет 2 каналов доступа к памяти. Однако усложняет архитектуру процессора и возникает возможность конфликтов между банками памяти (для инструкций писать данные и наоборот)

Включающий / исключающий 
Инклюзивное построение – данные кеш-линий дублируются. БОльший кеш включает в себя данные меньшего + что-то свое. Не очень эффективное использование памяти
Эксклюзивное построение – данные не дублируются. Выигрываем в использовании памяти, но немного проигрываем в скорости доступа
Гибридные варианты 
Частный / общий – количество обслуживаемых кешем процессоров. Частный обеспечивает скорость доступа ядра, однако возможно дублирование данных и конфликты. Общий сокращает количество промахов, вероятность дублирования и требует постоянную синхронизацию доступа 
Уровни кеширования в процессорах:
L0 (часто не выделяют) – очень специфичен, неотчуждаем от процессора и чуть ли не является частью него. Для стека, int / float чисел, обычно в доступе за такт
L1 – физическая часть процессора, но все же разделенный кеш (данные/инструкции) 
L2 – уже достаточно большой (до 12 Мб), унифицированный, часто общий.
L3 – совсем большие, ориентированы на оптимизацию IO, доступа к памяти
L4 – экзотика для серверов и мейнфреймов, предназначены для оптимизации интерфейса доступа к очень большой памяти

28. Когерентность кеш-памяти. Возможные состояния кеш линий. Механизмы обмена информацией между кешами: справочник, отслеживание и перехват. CAP теорема.
Когерентность кеш-памяти – целостность данных в кешах процессора и памяти. Проблемы с ней возникают  из-за параллельного доступа к данным (чтение / запись) множеством акторов (процессорные ядра, DMA). Необходимо обеспечить синхронизацию кешей, не погубив производительность.
Возможные состояния кеш-линий (MOESI):
Модифицировано – свежие уникальные данные, еще никто не знает, следовательно в других процессорах значение некорректное 
Владелец – только одна запись в процессоре может быть owned кем-то одним 
Эксклюзивное – свежие данные, соответствуют памяти, нигде в других кешах нет 
Разделяемое – содержит свежие данные, имеют копии. То есть при изменении надо оповестить другие места хранения
Не актуальное – когда-то прочитали, но уже изменены и некорректны
Обмен информацией о состоянии кеш-линий:
Справочник – дополнительный блок (справочник) с информацией о всех кеш-линиях и адресах в памяти какие есть. Перед загрузкой записи осуществляется проверка через справочник. При изменении справочник либо обновляет, либо аннулирует другие кеши с этой записью. По факту становится узким горлышком, через которое все качается проверяется пишется, однако хорошо масштабируется путем добавления произвольного количества процессоров на шину к справочнику.
Отслеживание – кеш слушает изменения других, изменение уведомляет все остальные кеши процессоров по шине к памяти. То есть кеши отслеживают адресные линии на предмет обращений к данным своих кеш-линий. Если наблюдается запись – кеш помечает линию как “не актуально”. Характеризуется высокой скоростью, но плохой масштабируемостью (на каждый кеш нужно количество входов соразмерно с количеством всех остальных кешей)
Перехват – улучшенная версия отслеживания, где мы ловим не только сигнал об изменении, но и само изменение, чтобы обновить не просто состояние, а целиком данные. С точки зрения масштабируемости все становится еще более печальным
CAP теорема – напрямую не связана с кешами, но иллюстрирует разнообразие на практике и как все по-разному можно устроить. Относится к распределенным хранилищам и говорит, что при описании объемной распределенной системы есть 3 свойства:
Согласованность данных – при изменении данных в одном узле все остальные должны об этом знать
Доступность данных – при отсутствии одного из узлов невозможно гарантировать правильность ответа. Каждый запрос получает ответ, но без гарантии, что он содержит последнюю запись (каждый узел хранит уникальную информацию)
Устойчивость к разбиению – поддержание работы системы при произвольном разделении изначальной системы на части
29. Закон Мура. Закон Деннарда. Закон Амдала. Power-wall. Memory-wall. Их роль в развитии компьютерных систем. Источники роста производительности процессоров тогда и сегодня.
Закон Деннарда – физическое уменьшение размера транзисторов (как базового элемента), что влечет за собой увеличение скорости распространения сигнала (т.е. частоту процессора) и снижение энергопотребления. 
Особенности:
Дороговизна (физическая невозможность) дальнейшего уменьшения размера транзистора
Токи утечки (чем меньше размер, тем больше потери тока)
Power wall – ограничение по мощности процессора. На данный момент мы не можем сделать процессоры быстрее из-за энергопотребления (нельзя дать больше тока чем есть и эффективно отвести выделяемое тепло)
Dark Silicon – умышленно доставляемое пространство для отведения тепла процессора
Закон Мура – основанное на наблюдениях заключение о зависимости роста количества транзисторов и производительности процессоров (удваивается каждые 24 месяца). Однако он встречается с некоторыми сдерживающими факторами:
Закон Амдала – ограничение на рост производительности при распараллеливании алгоритмов. Ускорение выполнения программы за счет распараллеливания её инструкций на множестве вычислителей ограничено временем, необходимым для выполнения ее последовательных инструкций.
Накладные расходы на параллельные вычисления
Объективная сложность параллельного программирования
Доставка данных (затраты на IO)
Memory Wall – ограничение на рост производительности процессора в связи с низким ростом скорости доступа к памяти. То есть наращивать вычислительные мощности не имеет смысла, так мы не можем доставить к ним данные.
Все эти законы работали для увеличения производительности в прошлом, однако сейчас имеют слишком много сдерживающих факторов. Текущими областями роста являются 
Увеличение уровня специализации (железок под узкие задачи)
Адаптация структуры под задачу и параллелизм (GPU)
Реконфигурация (динамическое перестроение и перенаправление потоков данных под конкретную задачу)

30. Проблема обеспечения реального времени в современных компьютерных системах. Влияние параллелизма уровня инструкций, языков программирования высокого уровня, многозадачности и организации памяти.
Проблема обеспечения реального времени заключается в том, чтобы гарантировать, что задача будет выполнена в течение заданного времени. Это особенно важно для систем, в которых задержка или пропуск выполнения задачи может иметь серьезные последствия, например, для систем управления, систем безопасности или систем обработки сигналов.

Параллелизм уровня инструкций позволяет выполнять несколько инструкций одновременно. Это может повысить производительность системы, но может также привести к задержкам в выполнении задач реального времени. Это связано с тем, что инструкции могут выполняться в произвольном порядке, и система может не быть уверена, что задача будет выполнена в течение заданного времени.

Языки программирования высокого уровня могут сделать код более сложным и менее предсказуемым. Это может привести к снижению производительности системы и увеличению вероятности задержки в выполнении задач реального времени.

Многозадачность позволяет системе выполнять несколько задач одновременно. Это может повысить производительность системы, но может также привести к задержкам в выполнении задач реального времени. Это связано с тем, что система должна распределять ресурсы между задачами, и задача реального времени может быть поставлена в очередь за другими задачами.

Организация памяти может повлиять на производительность системы и вероятность задержки в выполнении задач реального времени. Например, если система использует виртуальную память, то задача реального времени может быть вытеснена из оперативной памяти другой задачей. Это может привести к задержке в выполнении задачи реального времени. Также можно привести в пример многоуровневые кеши и блокировку памяти ее обновлением (DRAM) и DMA

Методы обеспечения реального времени в современных компьютерных системах:
Операционные системы реального времени (ОС РВ): Специально разработанные операционные системы, которые обеспечивают гарантированное выполнение задач и обработку событий в строго определенные промежутки времени. ОС РВ допускают предсказуемость и быстродействие даже в условиях высокой нагрузки.
Планирование в реальном времени: Применяются различные алгоритмы планирования для определения приоритетов и управления выполнением задач в реальном времени. Некоторые из них включают алгоритмы с фиксированным временным интервалом (Fixed Interval Scheduling), Rate-Monotonic Scheduling, Earliest Deadline First и другие.
Аппаратная поддержка в реальном времени: Некоторые компьютерные системы имеют специальную аппаратную поддержку, такую как сопроцессоры в реальном времени (Real-Time Coprocessors) или аппаратные таймеры, которые обеспечивают точное измерение и управление временными интервалами.
Изоляция и приоритезация: Для обеспечения реального времени, критические задачи могут быть изолированы и иметь приоритет над другими задачами в системе. Используются механизмы приоритетов, прерываний, блокировок и других методов, чтобы гарантировать выполнение важных задач в заданные сроки.
Оптимизация производительности и латентности: В компьютерных системах, где требуется реальное время, проводятся специальные оптимизации и настройки, чтобы уменьшить задержки и увеличить производительность. Это может включать оптимизацию кода, минимизацию использования внешних устройств с высокой степенью блокировки и т.д.
Верификация и тестирование (Timed Input Output Automata): Реальное время требует тщательной верификации и тестирования системы. Это включает использование средств проверки временной границы (Boundary Checking), анализ временного выполнения (Timing Analysis), симуляцию и другие методы, чтобы убедиться, что система отвечает требованиям реального времени.

